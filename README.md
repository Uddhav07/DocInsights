## DocInsights

talk to documents using local LLM with the power of RAG

# Installation
````
pip install -r requirements.txt
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
````
--in a seperate window--
````
ollama pull qwen2:0.5b
ollama pull gemma:2b
python -m streamlit run streamlit_app.py
````
Preview



https://github.com/Uddhav07/DocInsights/assets/93899908/b2baecf5-8328-4418-ac9f-b74fc1efab73

